{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp experiments.cult_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cult.core.cult import CULT, CULTTrainer\n",
    "from cult.core.models import FCEncoder, FCDecoder\n",
    "from cult.core.datasets.moving_mnist import CommonMNIST, CommonFashionMNIST\n",
    "from cult.core.utils import show_batch, rec_likelihood\n",
    "from cult.config import DATA_PATH\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cult Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "mnist_train = CommonMNIST(DATA_PATH, train=True, transform=ToTensor())\n",
    "mnist_test = CommonMNIST(DATA_PATH, train=False, transform=ToTensor())\n",
    "mnist_train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "mnist_test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "mnist_test_batch, _ = iter(mnist_test_loader).next()\n",
    "\n",
    "fashion_train = CommonFashionMNIST(DATA_PATH, train=True, transform=ToTensor())\n",
    "fashion_test = CommonFashionMNIST(DATA_PATH, train=False, transform=ToTensor())\n",
    "fashion_train_loader = DataLoader(fashion_train, batch_size=batch_size, shuffle=True)\n",
    "fashion_test_loader = DataLoader(fashion_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "fashion_test_batch, _ = iter(fashion_test_loader).next()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FashionMNIST -> MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "lr = 1e-3\n",
    "kl_scale = 1\n",
    "e_prox_scale = 1 #might need to scale?\n",
    "d_prox_scale = 1 #might need to scale\n",
    "encoder_type = FCEncoder\n",
    "decoder_type = FCDecoder\n",
    "final_size = 50\n",
    "latents = 16\n",
    "max_envs = 7\n",
    "atyp_min = .25\n",
    "atyp_max = 1.4\n",
    "env_optim = torch.optim.Adam\n",
    "env_lr=1e-4\n",
    "env_epochs = 1 #increasing due to poor performance\n",
    "replay_batch_size = 64\n",
    "steps_per_save = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss=882.2250366210938, rec_loss=323.95263671875, total_div_loss=11.78816032409668\n",
      "epoch: 1, loss=841.1382446289062, rec_loss=280.364501953125, total_div_loss=15.096327781677246\n",
      "epoch: 2, loss=833.1748657226562, rec_loss=271.33251953125, total_div_loss=16.35938262939453\n",
      "epoch: 3, loss=830.1004028320312, rec_loss=267.8424072265625, total_div_loss=16.83312225341797\n",
      "epoch: 4, loss=828.0590209960938, rec_loss=265.6373596191406, total_div_loss=17.026012420654297\n",
      "epoch: 5, loss=826.6766357421875, rec_loss=264.2637634277344, total_div_loss=17.06443214416504\n",
      "epoch: 6, loss=825.9876098632812, rec_loss=263.4705505371094, total_div_loss=17.175325393676758\n",
      "epoch: 7, loss=825.3734741210938, rec_loss=262.8834228515625, total_div_loss=17.170766830444336\n",
      "epoch: 8, loss=825.010498046875, rec_loss=262.45904541015625, total_div_loss=17.24131202697754\n",
      "epoch: 9, loss=824.64599609375, rec_loss=262.03948974609375, total_div_loss=17.305383682250977\n",
      "epoch: 0, loss=473.9437561035156, rec_loss=178.5197296142578, total_div_loss=12.00723648071289\n",
      "epoch: 1, loss=456.5731506347656, rec_loss=163.85107421875, total_div_loss=12.809956550598145\n",
      "epoch: 2, loss=452.5790710449219, rec_loss=159.49996948242188, total_div_loss=13.580565452575684\n",
      "epoch: 3, loss=450.21484375, rec_loss=156.5223388671875, total_div_loss=14.383627891540527\n",
      "epoch: 4, loss=448.4455871582031, rec_loss=154.4945068359375, total_div_loss=15.173524856567383\n",
      "epoch: 5, loss=447.1588134765625, rec_loss=153.26422119140625, total_div_loss=15.41264820098877\n",
      "epoch: 6, loss=446.46112060546875, rec_loss=152.52110290527344, total_div_loss=15.66240406036377\n",
      "epoch: 7, loss=445.3141784667969, rec_loss=151.9559783935547, total_div_loss=15.791462898254395\n",
      "epoch: 8, loss=445.74609375, rec_loss=151.59934997558594, total_div_loss=15.957612991333008\n",
      "epoch: 9, loss=445.08099365234375, rec_loss=151.18638610839844, total_div_loss=15.990188598632812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [02:37<00:00, 22.48s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for i in range(1):\n",
    "    name = f\"fash_to_mnist_{i}\"\n",
    "    cult_trainer = CULTTrainer(name, optimizer, lr, kl_scale, e_prox_scale, d_prox_scale, encoder_type, decoder_type, final_size, latents, max_envs, atyp_min, atyp_max, env_optim, env_lr, env_epochs, replay_batch_size, steps_per_save, device)\n",
    "    cult_trainer.train(fashion_train_loader, epochs, [fashion_test_batch, mnist_test_batch])\n",
    "    cult_trainer.train(mnist_train_loader, epochs, [fashion_test_batch, mnist_test_batch])\n",
    "    cult_trainer.train_latent_classifiers([fashion_train_loader, mnist_train_loader], [fashion_test_loader, mnist_test_loader], [\"fashion_mnist\", \"mnist\"], [10, 10], epochs=3, lr=1e-2, verbose=False)\n",
    "    cult_trainer.model.eval()\n",
    "    cult_trainer.model.env_net.eval()\n",
    "    fashion_rec_loss = cult_trainer.rec_loss(fashion_test_loader)\n",
    "    mnist_rec_loss = cult_trainer.rec_loss(mnist_test_loader)\n",
    "    cult_trainer.writer.add_scalar(\"eval/fashion_rec_loss\", fashion_rec_loss)\n",
    "    cult_trainer.writer.add_scalar(\"eval/mnist_recc_loss\", mnist_rec_loss)\n",
    "    fashion_env_acc = cult_trainer.env_accuracy(fashion_test_loader, 0)\n",
    "    mnist_env_acc = cult_trainer.env_accuracy(mnist_test_loader, 1)\n",
    "    cult_trainer.writer.add_scalar(\"eval/fashion_env_acc\", fashion_env_acc)\n",
    "    cult_trainer.writer.add_scalar(\"eval/mnist_env_acc\", mnist_env_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST -> Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "lr = 1e-3\n",
    "kl_scale = 1\n",
    "e_prox_scale = 1 #might need to scale?\n",
    "d_prox_scale = 1 #might need to scale\n",
    "encoder_type = FCEncoder\n",
    "decoder_type = FCDecoder\n",
    "final_size = 50\n",
    "latents = 16\n",
    "max_envs = 7\n",
    "atyp_min = .25\n",
    "atyp_max = 1.4\n",
    "env_optim = torch.optim.Adam\n",
    "env_lr=1e-4\n",
    "env_epochs = 1 #increasing due to poor performance\n",
    "replay_batch_size = 64\n",
    "steps_per_save = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss=762.3403930664062, rec_loss=208.43739318847656, total_div_loss=7.153684139251709\n",
      "epoch: 1, loss=726.2791137695312, rec_loss=169.60476684570312, total_div_loss=9.923151969909668\n",
      "epoch: 2, loss=720.3603515625, rec_loss=161.651123046875, total_div_loss=11.953137397766113\n",
      "epoch: 3, loss=716.0773315429688, rec_loss=157.0636444091797, total_div_loss=13.183549880981445\n",
      "epoch: 4, loss=714.6477661132812, rec_loss=154.5414581298828, total_div_loss=14.095521926879883\n",
      "epoch: 5, loss=713.4898071289062, rec_loss=152.78001403808594, total_div_loss=14.73049259185791\n",
      "epoch: 6, loss=712.3055419921875, rec_loss=151.52017211914062, total_div_loss=15.201375007629395\n",
      "epoch: 7, loss=712.08740234375, rec_loss=150.65318298339844, total_div_loss=15.589981079101562\n",
      "epoch: 8, loss=711.1619873046875, rec_loss=149.8383331298828, total_div_loss=15.908149719238281\n",
      "epoch: 9, loss=710.6917724609375, rec_loss=149.17279052734375, total_div_loss=16.139873504638672\n",
      "epoch: 0, loss=494.6817321777344, rec_loss=294.57196044921875, total_div_loss=20.333349227905273\n",
      "epoch: 1, loss=470.79693603515625, rec_loss=275.0189208984375, total_div_loss=19.20327377319336\n",
      "epoch: 2, loss=465.8271484375, rec_loss=270.8266906738281, total_div_loss=19.089012145996094\n",
      "epoch: 3, loss=463.45849609375, rec_loss=268.9288635253906, total_div_loss=19.075246810913086\n",
      "epoch: 4, loss=461.7028503417969, rec_loss=267.5934753417969, total_div_loss=19.00122833251953\n",
      "epoch: 5, loss=460.34735107421875, rec_loss=266.6353454589844, total_div_loss=18.888378143310547\n",
      "epoch: 6, loss=459.3982238769531, rec_loss=266.0683288574219, total_div_loss=19.01408576965332\n",
      "epoch: 7, loss=458.6552429199219, rec_loss=265.44635009765625, total_div_loss=18.825061798095703\n",
      "epoch: 8, loss=458.07708740234375, rec_loss=264.96478271484375, total_div_loss=18.83652114868164\n",
      "epoch: 9, loss=457.5338134765625, rec_loss=264.6739196777344, total_div_loss=18.84014320373535\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.8706)\n",
      "epoch 1 acc tensor(0.8895)\n",
      "epoch 2 acc tensor(0.8975)\n",
      "epoch 0 acc tensor(0.6968)\n",
      "epoch 1 acc tensor(0.7245)\n",
      "epoch 2 acc tensor(0.7278)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:26<02:41, 26.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.8771)\n",
      "epoch 1 acc tensor(0.8940)\n",
      "epoch 2 acc tensor(0.8921)\n",
      "epoch 0 acc tensor(0.7060)\n",
      "epoch 1 acc tensor(0.7268)\n",
      "epoch 2 acc tensor(0.7430)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [00:54<02:15, 27.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.8844)\n",
      "epoch 1 acc tensor(0.8959)\n",
      "epoch 2 acc tensor(0.8954)\n",
      "epoch 0 acc tensor(0.7060)\n",
      "epoch 1 acc tensor(0.7257)\n",
      "epoch 2 acc tensor(0.7198)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [01:24<01:54, 28.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.8438)\n",
      "epoch 1 acc tensor(0.8588)\n",
      "epoch 2 acc tensor(0.8683)\n",
      "epoch 0 acc tensor(0.7466)\n",
      "epoch 1 acc tensor(0.7586)\n",
      "epoch 2 acc tensor(0.7581)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [01:53<01:26, 28.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.8624)\n",
      "epoch 1 acc tensor(0.8762)\n",
      "epoch 2 acc tensor(0.8817)\n",
      "epoch 0 acc tensor(0.7528)\n",
      "epoch 1 acc tensor(0.7672)\n",
      "epoch 2 acc tensor(0.7641)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [02:23<00:58, 29.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.8604)\n",
      "epoch 1 acc tensor(0.8748)\n",
      "epoch 2 acc tensor(0.8748)\n",
      "epoch 0 acc tensor(0.7665)\n",
      "epoch 1 acc tensor(0.7631)\n",
      "epoch 2 acc tensor(0.7744)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [02:51<00:28, 28.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.8591)\n",
      "epoch 1 acc tensor(0.8624)\n",
      "epoch 2 acc tensor(0.8672)\n",
      "epoch 0 acc tensor(0.7657)\n",
      "epoch 1 acc tensor(0.7718)\n",
      "epoch 2 acc tensor(0.7692)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [03:20<00:00, 28.62s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for i in range(1):\n",
    "    name = f\"mnist_to_fash_{i}\"\n",
    "    cult_trainer = CULTTrainer(name, optimizer, lr, kl_scale, e_prox_scale, d_prox_scale, encoder_type, decoder_type, final_size, latents, max_envs, atyp_min, atyp_max, env_optim, env_lr, env_epochs, replay_batch_size, steps_per_save, device)\n",
    "    cult_trainer.train(mnist_train_loader, epochs, [mnist_test_batch, fashion_test_batch])\n",
    "    cult_trainer.train(fashion_train_loader, epochs, [mnist_test_batch, fashion_test_batch])\n",
    "    cult_trainer.train_latent_classifiers([mnist_train_loader, fashion_train_loader], [mnist_test_loader, fashion_test_loader], [\"mnist\", \"fashion_mnist\"], [10, 10], epochs=3, lr=1e-2)\n",
    "    cult_trainer.model.eval()\n",
    "    fashion_rec_loss = cult_trainer.rec_loss(fashion_test_loader)\n",
    "    mnist_rec_loss = cult_trainer.rec_loss(mnist_test_loader)\n",
    "    cult_trainer.writer.add_scalar(\"eval/fashion_rec_loss\", fashion_rec_loss)\n",
    "    cult_trainer.writer.add_scalar(\"eval/mnist_recc_loss\", mnist_rec_loss)\n",
    "    fashion_env_acc = cult_trainer.env_accuracy(fashion_test_loader, 1)\n",
    "    mnist_env_acc = cult_trainer.env_accuracy(mnist_test_loader, 0)\n",
    "    cult_trainer.writer.add_scalar(\"eval/fashion_env_acc\", fashion_env_acc)\n",
    "    cult_trainer.writer.add_scalar(\"eval/mnist_env_acc\", mnist_env_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Update: FashionMNIST -> MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "lr = 1e-3\n",
    "kl_scale = 1\n",
    "e_prox_scale = 1 #might need to scale?\n",
    "d_prox_scale = 1 #might need to scale\n",
    "encoder_type = FCEncoder\n",
    "decoder_type = FCDecoder\n",
    "final_size = 50\n",
    "latents = 16\n",
    "max_envs = 7\n",
    "atyp_min = .25\n",
    "atyp_max = 1.4\n",
    "env_optim = torch.optim.Adam\n",
    "env_lr=1e-4\n",
    "env_epochs = 1 #increasing due to poor performance\n",
    "replay_batch_size = 64\n",
    "steps_per_save = 2500\n",
    "steps_per_reset = 500 # if None, replay model only updated at new environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss=795.631591796875, rec_loss=322.287353515625, total_div_loss=13.273159980773926\n",
      "epoch: 1, loss=614.6732788085938, rec_loss=279.1069030761719, total_div_loss=16.17925453186035\n",
      "epoch: 2, loss=589.9298095703125, rec_loss=270.7331237792969, total_div_loss=17.855920791625977\n",
      "epoch: 3, loss=580.2642211914062, rec_loss=267.1777648925781, total_div_loss=18.885953903198242\n",
      "epoch: 4, loss=575.18359375, rec_loss=264.7123107910156, total_div_loss=19.74139976501465\n",
      "epoch: 5, loss=571.9389038085938, rec_loss=263.0014343261719, total_div_loss=20.506607055664062\n",
      "epoch: 6, loss=567.923095703125, rec_loss=261.94927978515625, total_div_loss=20.95893096923828\n",
      "epoch: 7, loss=566.7766723632812, rec_loss=261.3365478515625, total_div_loss=21.13743782043457\n",
      "epoch: 8, loss=564.888671875, rec_loss=260.90228271484375, total_div_loss=21.165355682373047\n",
      "epoch: 9, loss=563.883056640625, rec_loss=260.6723937988281, total_div_loss=21.216205596923828\n",
      "epoch: 0, loss=443.0996398925781, rec_loss=181.3782958984375, total_div_loss=11.86132526397705\n",
      "epoch: 1, loss=368.70782470703125, rec_loss=162.7717742919922, total_div_loss=13.700567245483398\n",
      "epoch: 2, loss=349.0942687988281, rec_loss=156.6599578857422, total_div_loss=15.48841381072998\n",
      "epoch: 3, loss=341.5820007324219, rec_loss=153.08177185058594, total_div_loss=16.956628799438477\n",
      "epoch: 4, loss=338.0351257324219, rec_loss=151.16665649414062, total_div_loss=17.938617706298828\n",
      "epoch: 5, loss=336.1946716308594, rec_loss=150.20623779296875, total_div_loss=18.367977142333984\n",
      "epoch: 6, loss=335.1286315917969, rec_loss=149.53799438476562, total_div_loss=18.55385398864746\n",
      "epoch: 7, loss=333.7279968261719, rec_loss=148.98257446289062, total_div_loss=18.763702392578125\n",
      "epoch: 8, loss=332.917236328125, rec_loss=148.5669403076172, total_div_loss=18.847305297851562\n",
      "epoch: 9, loss=332.5807189941406, rec_loss=148.27069091796875, total_div_loss=18.935264587402344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.7449)\n",
      "epoch 1 acc tensor(0.7678)\n",
      "epoch 2 acc tensor(0.7701)\n",
      "epoch 0 acc tensor(0.7247)\n",
      "epoch 1 acc tensor(0.7555)\n",
      "epoch 2 acc tensor(0.7667)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:26<02:40, 26.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.7427)\n",
      "epoch 1 acc tensor(0.7534)\n",
      "epoch 2 acc tensor(0.7633)\n",
      "epoch 0 acc tensor(0.7429)\n",
      "epoch 1 acc tensor(0.7700)\n",
      "epoch 2 acc tensor(0.7907)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [00:53<02:13, 26.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.7498)\n",
      "epoch 1 acc tensor(0.7550)\n",
      "epoch 2 acc tensor(0.7717)\n",
      "epoch 0 acc tensor(0.6662)\n",
      "epoch 1 acc tensor(0.7176)\n",
      "epoch 2 acc tensor(0.7382)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [01:20<01:46, 26.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.7279)\n",
      "epoch 1 acc tensor(0.7391)\n",
      "epoch 2 acc tensor(0.7277)\n",
      "epoch 0 acc tensor(0.7157)\n",
      "epoch 1 acc tensor(0.7314)\n",
      "epoch 2 acc tensor(0.7422)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [01:47<01:20, 26.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.7379)\n",
      "epoch 1 acc tensor(0.7470)\n",
      "epoch 2 acc tensor(0.7566)\n",
      "epoch 0 acc tensor(0.8097)\n",
      "epoch 1 acc tensor(0.8358)\n",
      "epoch 2 acc tensor(0.8469)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [02:14<00:54, 27.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.7139)\n",
      "epoch 1 acc tensor(0.7343)\n",
      "epoch 2 acc tensor(0.7412)\n",
      "epoch 0 acc tensor(0.8287)\n",
      "epoch 1 acc tensor(0.8377)\n",
      "epoch 2 acc tensor(0.8542)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [02:41<00:27, 27.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.7008)\n",
      "epoch 1 acc tensor(0.7193)\n",
      "epoch 2 acc tensor(0.7355)\n",
      "epoch 0 acc tensor(0.8493)\n",
      "epoch 1 acc tensor(0.8697)\n",
      "epoch 2 acc tensor(0.8767)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [03:12<00:00, 27.47s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for i in range(1):\n",
    "    name = f\"fixed_fash_to_mnist_{i}\"\n",
    "    cult_trainer = CULTTrainer(name, optimizer, lr, kl_scale, e_prox_scale, d_prox_scale, encoder_type, decoder_type, final_size, latents, max_envs, atyp_min, atyp_max, env_optim, env_lr, env_epochs, replay_batch_size, steps_per_save, device, steps_per_reset)\n",
    "    cult_trainer.train(fashion_train_loader, epochs, [fashion_test_batch, mnist_test_batch])\n",
    "    cult_trainer.train(mnist_train_loader, epochs, [fashion_test_batch, mnist_test_batch])\n",
    "    cult_trainer.train_latent_classifiers([fashion_train_loader, mnist_train_loader], [fashion_test_loader, mnist_test_loader], [\"fashion_mnist\", \"mnist\"], [10, 10], epochs=3, lr=1e-2)\n",
    "    cult_trainer.model.eval()\n",
    "    fashion_rec_loss = cult_trainer.rec_loss(fashion_test_loader)\n",
    "    mnist_rec_loss = cult_trainer.rec_loss(mnist_test_loader)\n",
    "    cult_trainer.writer.add_scalar(\"eval/fashion_rec_loss\", fashion_rec_loss)\n",
    "    cult_trainer.writer.add_scalar(\"eval/mnist_recc_loss\", mnist_rec_loss)\n",
    "    fashion_env_acc = cult_trainer.env_accuracy(fashion_test_loader, 0)\n",
    "    mnist_env_acc = cult_trainer.env_accuracy(mnist_test_loader, 1)\n",
    "    cult_trainer.writer.add_scalar(\"eval/fashion_env_acc\", fashion_env_acc)\n",
    "    cult_trainer.writer.add_scalar(\"eval/mnist_env_acc\", mnist_env_acc)\n",
    "\n",
    "    #cult_trainer.train_latent_classifiers([fashion_train_loader, mnist_train_loader], [fashion_test_loader, mnist_test_loader], [\"fashion_mnist\", \"mnist\"], [10, 10], epochs=3, lr=1e-2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Replay: FashionMNIST -> MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "lr = 1e-3\n",
    "kl_scale = 1\n",
    "e_prox_scale = 0 \n",
    "d_prox_scale = 0 \n",
    "encoder_type = FCEncoder\n",
    "decoder_type = FCDecoder\n",
    "final_size = 50\n",
    "latents = 16\n",
    "max_envs = 7\n",
    "atyp_min = .25\n",
    "atyp_max = 1.4\n",
    "env_optim = torch.optim.Adam\n",
    "env_lr=1e-4\n",
    "env_epochs = 1\n",
    "replay_batch_size = 64\n",
    "steps_per_save = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss=334.0847473144531, rec_loss=323.16497802734375, total_div_loss=10.919363021850586\n",
      "epoch: 1, loss=293.1953430175781, rec_loss=279.8336181640625, total_div_loss=13.361682891845703\n",
      "epoch: 2, loss=285.898681640625, rec_loss=271.314453125, total_div_loss=14.58430290222168\n",
      "epoch: 3, loss=282.6383361816406, rec_loss=266.7991638183594, total_div_loss=15.83903980255127\n",
      "epoch: 4, loss=281.0431213378906, rec_loss=264.6848449707031, total_div_loss=16.358247756958008\n",
      "epoch: 5, loss=280.0467224121094, rec_loss=263.36431884765625, total_div_loss=16.682052612304688\n",
      "epoch: 6, loss=279.457275390625, rec_loss=262.6441345214844, total_div_loss=16.813255310058594\n",
      "epoch: 7, loss=279.2010498046875, rec_loss=262.20538330078125, total_div_loss=16.99568748474121\n",
      "epoch: 8, loss=278.66064453125, rec_loss=261.7117614746094, total_div_loss=16.948820114135742\n",
      "epoch: 9, loss=278.4388732910156, rec_loss=261.4319152832031, total_div_loss=17.00688934326172\n",
      "epoch: 0, loss=186.96524047851562, rec_loss=177.83444213867188, total_div_loss=9.130690574645996\n",
      "epoch: 1, loss=172.6964111328125, rec_loss=161.37258911132812, total_div_loss=11.323748588562012\n",
      "epoch: 2, loss=169.3922576904297, rec_loss=156.77175903320312, total_div_loss=12.620512962341309\n",
      "epoch: 3, loss=167.86233520507812, rec_loss=154.4796142578125, total_div_loss=13.382607460021973\n",
      "epoch: 4, loss=166.9246826171875, rec_loss=152.841796875, total_div_loss=14.082767486572266\n",
      "epoch: 5, loss=166.13124084472656, rec_loss=151.56082153320312, total_div_loss=14.570476531982422\n",
      "epoch: 6, loss=165.5471954345703, rec_loss=150.66098022460938, total_div_loss=14.886265754699707\n",
      "epoch: 7, loss=165.2813720703125, rec_loss=150.13436889648438, total_div_loss=15.146838188171387\n",
      "epoch: 8, loss=165.01258850097656, rec_loss=149.70120239257812, total_div_loss=15.311249732971191\n",
      "epoch: 9, loss=164.76104736328125, rec_loss=149.3272705078125, total_div_loss=15.43368148803711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.7534)\n",
      "epoch 1 acc tensor(0.7640)\n",
      "epoch 2 acc tensor(0.7623)\n",
      "epoch 0 acc tensor(0.6739)\n",
      "epoch 1 acc tensor(0.7167)\n",
      "epoch 2 acc tensor(0.7254)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1/7 [00:26<02:39, 26.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.7503)\n",
      "epoch 1 acc tensor(0.7485)\n",
      "epoch 2 acc tensor(0.7501)\n",
      "epoch 0 acc tensor(0.6114)\n",
      "epoch 1 acc tensor(0.6622)\n",
      "epoch 2 acc tensor(0.6785)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 2/7 [00:53<02:13, 26.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.7479)\n",
      "epoch 1 acc tensor(0.7631)\n",
      "epoch 2 acc tensor(0.7647)\n",
      "epoch 0 acc tensor(0.5461)\n",
      "epoch 1 acc tensor(0.6256)\n",
      "epoch 2 acc tensor(0.6582)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 3/7 [01:23<01:53, 28.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.7416)\n",
      "epoch 1 acc tensor(0.7559)\n",
      "epoch 2 acc tensor(0.7550)\n",
      "epoch 0 acc tensor(0.7373)\n",
      "epoch 1 acc tensor(0.7507)\n",
      "epoch 2 acc tensor(0.7710)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 4/7 [01:54<01:28, 29.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.6851)\n",
      "epoch 1 acc tensor(0.7035)\n",
      "epoch 2 acc tensor(0.7096)\n",
      "epoch 0 acc tensor(0.7858)\n",
      "epoch 1 acc tensor(0.8129)\n",
      "epoch 2 acc tensor(0.8188)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 5/7 [02:26<01:00, 30.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.6960)\n",
      "epoch 1 acc tensor(0.7041)\n",
      "epoch 2 acc tensor(0.7122)\n",
      "epoch 0 acc tensor(0.8285)\n",
      "epoch 1 acc tensor(0.8380)\n",
      "epoch 2 acc tensor(0.8507)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 6/7 [02:56<00:30, 30.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 acc tensor(0.6782)\n",
      "epoch 1 acc tensor(0.6993)\n",
      "epoch 2 acc tensor(0.7129)\n",
      "epoch 0 acc tensor(0.8243)\n",
      "epoch 1 acc tensor(0.8412)\n",
      "epoch 2 acc tensor(0.8485)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [03:24<00:00, 29.17s/it]\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for i in range(1):\n",
    "    name = f\"no_replay_fash_to_mnist_{i}\"\n",
    "    cult_trainer = CULTTrainer(name, optimizer, lr, kl_scale, e_prox_scale, d_prox_scale, encoder_type, decoder_type, final_size, latents, max_envs, atyp_min, atyp_max, env_optim, env_lr, env_epochs, replay_batch_size, steps_per_save, device)\n",
    "    cult_trainer.train(fashion_train_loader, epochs, [fashion_test_batch, mnist_test_batch])\n",
    "    cult_trainer.train(mnist_train_loader, epochs, [fashion_test_batch, mnist_test_batch])\n",
    "    cult_trainer.train_latent_classifiers([fashion_train_loader, mnist_train_loader], [fashion_test_loader, mnist_test_loader], [\"fashion_mnist\", \"mnist\"], [10, 10], epochs=3, lr=1e-2)\n",
    "    cult_trainer.model.eval()\n",
    "    fashion_rec_loss = cult_trainer.rec_loss(fashion_test_loader)\n",
    "    mnist_rec_loss = cult_trainer.rec_loss(mnist_test_loader)\n",
    "    cult_trainer.writer.add_scalar(\"eval/fashion_rec_loss\", fashion_rec_loss)\n",
    "    cult_trainer.writer.add_scalar(\"eval/mnist_recc_loss\", mnist_rec_loss)\n",
    "    fashion_env_acc = cult_trainer.env_accuracy(fashion_test_loader, 0)\n",
    "    mnist_env_acc = cult_trainer.env_accuracy(mnist_test_loader, 1)\n",
    "    cult_trainer.writer.add_scalar(\"eval/fashion_env_acc\", fashion_env_acc)\n",
    "    cult_trainer.writer.add_scalar(\"eval/mnist_env_acc\", mnist_env_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then we should be good to go - once we get the env stuff figured out, we'll run the following expeiments:\n",
    "FashionMNIST -> MNIST (5x)\n",
    "MNIST -> FashionMNIST (5x)\n",
    "\n",
    "FashionMNIST -> MNIST static update (5x)\n",
    "MNIST -> FashionMNIST static update (5x)\n",
    "\n",
    "FashionMNIST -> MNIST no replay (5x)\n",
    "MNIST -> FashionMNIST no replay (5x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('cult')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
