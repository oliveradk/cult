{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp experiments.cult_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cult.core.cult import CULT, CULTTrainer\n",
    "from cult.core.models import FCEncoder, FCDecoder\n",
    "from cult.core.datasets.moving_mnist import CommonMNIST, CommonFashionMNIST\n",
    "from cult.core.utils import show_batch\n",
    "from cult.config import DATA_PATH\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cult Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "mnist_train = CommonMNIST(DATA_PATH, train=True, transform=ToTensor())\n",
    "mnist_test = CommonMNIST(DATA_PATH, train=False, transform=ToTensor())\n",
    "mnist_train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "mnist_test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "mnist_test_batch, _ = iter(mnist_test_loader).next()\n",
    "\n",
    "fashion_train = CommonFashionMNIST(DATA_PATH, train=True, transform=ToTensor())\n",
    "fashion_test = CommonFashionMNIST(DATA_PATH, train=False, transform=ToTensor())\n",
    "fashion_train_loader = DataLoader(fashion_train, batch_size=batch_size, shuffle=True)\n",
    "fashion_test_loader = DataLoader(fashion_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "fashion_test_batch, _ = iter(fashion_test_loader).next()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FashionMNIST -> MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam\n",
    "lr = 1e-3\n",
    "kl_scale = 1\n",
    "e_prox_scale = 1 #might need to scale?\n",
    "d_prox_scale = 1 #might need to scale\n",
    "encoder_type = FCEncoder\n",
    "decoder_type = FCDecoder\n",
    "final_size = 50\n",
    "latents = 16\n",
    "max_envs = 7\n",
    "atyp_min = .25\n",
    "atyp_max = 1.4\n",
    "env_optim = torch.optim.Adam\n",
    "env_lr=1e-4\n",
    "env_epochs = 1 #increasing due to poor performance\n",
    "replay_batch_size = 64\n",
    "steps_per_save = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss=886.5707397460938, rec_loss=328.4096374511719, total_div_loss=11.265183448791504\n",
      "epoch: 0, loss=548.5853271484375, rec_loss=181.38121032714844, total_div_loss=8.922162055969238\n",
      "epoch: 0, loss=883.0299072265625, rec_loss=324.126953125, total_div_loss=12.292306900024414\n",
      "epoch: 0, loss=550.9530029296875, rec_loss=181.06832885742188, total_div_loss=9.10499382019043\n",
      "epoch: 0, loss=884.5418701171875, rec_loss=325.7725830078125, total_div_loss=11.916460990905762\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/03a_experiments.cult_experiments.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/03a_experiments.cult_experiments.ipynb#ch0000008?line=3'>4</a>\u001b[0m cult_trainer \u001b[39m=\u001b[39m CULTTrainer(name, optimizer, lr, kl_scale, e_prox_scale, d_prox_scale, encoder_type, decoder_type, final_size, latents, max_envs, atyp_min, atyp_max, env_optim, env_lr, env_epochs, replay_batch_size, steps_per_save, device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/03a_experiments.cult_experiments.ipynb#ch0000008?line=4'>5</a>\u001b[0m cult_trainer\u001b[39m.\u001b[39mtrain(fashion_train_loader, epochs, [fashion_test_batch, mnist_test_batch])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/03a_experiments.cult_experiments.ipynb#ch0000008?line=5'>6</a>\u001b[0m cult_trainer\u001b[39m.\u001b[39;49mtrain(mnist_train_loader, epochs, [fashion_test_batch, mnist_test_batch])\n",
      "File \u001b[0;32m~/NotebookProjects/lifelong_disrep/cult/core/cult.py:246\u001b[0m, in \u001b[0;36mCULTTrainer.train\u001b[0;34m(self, loader, epochs, test_batches, verbose)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/cult/core/cult.py?line=242'>243</a>\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/cult/core/cult.py?line=243'>244</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m--> <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/cult/core/cult.py?line=245'>246</a>\u001b[0m rec_x, mu, logvar, x_halu, rec_x_halo, z_halu_old, z_halu, s_halu, atyp, avg_env_loss, env_acc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(X)\n\u001b[1;32m    <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/cult/core/cult.py?line=247'>248</a>\u001b[0m rec_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(rec_likelihood(X, rec_x))\n\u001b[1;32m    <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/cult/core/cult.py?line=248'>249</a>\u001b[0m kl_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkl_scale \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mmean(torch\u001b[39m.\u001b[39msquare(kl_div_stdnorm(mu, logvar))) \u001b[39m#NOTE: should I square this?\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/cult/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/cult/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/cult/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/cult/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/cult/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/cult/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/cult/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/cult/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/NotebookProjects/lifelong_disrep/cult/core/cult.py:78\u001b[0m, in \u001b[0;36mCULT.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/cult/core/cult.py?line=75'>76</a>\u001b[0m s \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm \u001b[39m!=\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/cult/core/cult.py?line=76'>77</a>\u001b[0m z \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreparam(mu, logvar)\n\u001b[0;32m---> <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/cult/core/cult.py?line=77'>78</a>\u001b[0m rec_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecoder(z, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mint_to_vec(s, batch_size))\n\u001b[1;32m     <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/cult/core/cult.py?line=79'>80</a>\u001b[0m atyp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_atyp(z)\n\u001b[1;32m     <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/cult/core/cult.py?line=81'>82</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mm \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/cult/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/cult/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/cult/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/cult/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/cult/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/cult/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/cult/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/cult/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "for i in range(5):\n",
    "    name = f\"fash_to_mnist_{i}\"\n",
    "    cult_trainer = CULTTrainer(name, optimizer, lr, kl_scale, e_prox_scale, d_prox_scale, encoder_type, decoder_type, final_size, latents, max_envs, atyp_min, atyp_max, env_optim, env_lr, env_epochs, replay_batch_size, steps_per_save, device)\n",
    "    cult_trainer.train(fashion_train_loader, epochs, [fashion_test_batch, mnist_test_batch])\n",
    "    cult_trainer.train(mnist_train_loader, epochs, [fashion_test_batch, mnist_test_batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST -> Fashion MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "optimizer = torch.optim.Adam\n",
    "lr = 1e-3\n",
    "kl_scale = 1\n",
    "e_prox_scale = 1 #might need to scale?\n",
    "d_prox_scale = 1 #might need to scale\n",
    "encoder_type = FCEncoder\n",
    "decoder_type = FCDecoder\n",
    "final_size = 50\n",
    "latents = 16\n",
    "max_envs = 7\n",
    "atyp_min = .25\n",
    "atyp_max = 1.4\n",
    "env_optim = torch.optim.Adam\n",
    "env_lr=1e-4\n",
    "env_epochs = 1 #increasing due to poor performance\n",
    "replay_batch_size = 64\n",
    "steps_per_save = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for i in range(5):\n",
    "    name = f\"mnist_to_fash_{i}\"\n",
    "    cult_trainer = CULTTrainer(name, optimizer, lr, kl_scale, e_prox_scale, d_prox_scale, encoder_type, decoder_type, final_size, latents, max_envs, atyp_min, atyp_max, env_optim, env_lr, env_epochs, replay_batch_size, steps_per_save, device)\n",
    "    cult_trainer.train(mnist_train_loader, epochs, [mnist_test_batch, fashion_test_batch])\n",
    "    cult_trainer.train(fashion_train_loader, epochs, [mnist_test_batch, fashion_test_batch])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static Update: FashionMNIST -> MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: implement this in cult"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No Replay: FashionMNIST -> MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam\n",
    "lr = 1e-3\n",
    "kl_scale = 1\n",
    "e_prox_scale = 0 \n",
    "d_prox_scale = 0 \n",
    "encoder_type = FCEncoder\n",
    "decoder_type = FCDecoder\n",
    "final_size = 50\n",
    "latents = 16\n",
    "max_envs = 7\n",
    "atyp_min = .25\n",
    "atyp_max = 1e7\n",
    "env_optim = torch.optim.Adam\n",
    "env_lr=1e-4\n",
    "env_epochs = 1\n",
    "replay_batch_size = 64\n",
    "steps_per_save = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "for i in range(5):\n",
    "    name = f\"fash_to_mnist_{i}\"\n",
    "    cult_trainer = CULTTrainer(name, optimizer, lr, kl_scale, e_prox_scale, d_prox_scale, encoder_type, decoder_type, final_size, latents, max_envs, atyp_min, atyp_max, env_optim, env_lr, env_epochs, replay_batch_size, steps_per_save, device)\n",
    "    cult_trainer.train(fashion_train_loader, epochs, [fashion_test_batch, mnist_test_batch])\n",
    "    cult_trainer.train(mnist_train_loader, epochs, [fashion_test_batch, mnist_test_batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Then we should be good to go - once we get the env stuff figured out, we'll run the following expeiments:\n",
    "FashionMNIST -> MNIST (5x)\n",
    "MNIST -> FashionMNIST (5x)\n",
    "\n",
    "FashionMNIST -> MNIST static update (5x)\n",
    "MNIST -> FashionMNIST static update (5x)\n",
    "\n",
    "FashionMNIST -> MNIST no replay (5x)\n",
    "MNIST -> FashionMNIST no replay (5x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('cult')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
