{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp core.clvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from cmaes import CMA\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from vase.core.models import FCEncoder, FCDecoder, Encoder, Decoder, EnvironmentInference\n",
    "from vase.core.utils import rec_likelihood, disable_gradient, kl_div_stdnorm, euclidean, show_batch, save_model, load_model\n",
    "from vase.config import DATA_PATH, LOG_PATH, PARAM_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from vase.core.datasets.moving_mnist import CommonMNIST, CommonFashionMNIST, MovingMNIST, MovingFashionMNIST, FixedMNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "mnist_data = CommonMNIST(DATA_PATH, transform=ToTensor(), download=True)\n",
    "mnist_loader = DataLoader(mnist_data, batch_size=batch_size, shuffle=True)\n",
    "mnist_batch, _ = iter(mnist_loader).next()\n",
    "small_fashion = CommonFashionMNIST(DATA_PATH, transform=ToTensor())\n",
    "sf_loader = DataLoader(small_fashion, batch_size=batch_size, shuffle=True)\n",
    "sf_batch, _ = iter(sf_loader).next()\n",
    "fashion_data = MovingFashionMNIST(DATA_PATH, transform=ToTensor(), download=True)\n",
    "fashion_loader = DataLoader(fashion_data, batch_size, shuffle=True)\n",
    "fashion_batch, _, _ = iter(fashion_loader).next()\n",
    "mm_data = MovingMNIST(DATA_PATH, transform=ToTensor(), download=True)\n",
    "mm_loader = DataLoader(mm_data, batch_size, shuffle=True)\n",
    "mm_batch, _, _ = iter(mm_loader).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continually Learning Variational Autoencoder\n",
    "> Performs unsupervised continual representation learning with generative replay and environment likelihood detection\n",
    "\n",
    "Notes: assumes sequential tasks - \"local stationarity\" i.e. will stay on distribution long enough to learn it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CLVAE(nn.Module):\n",
    "    def __init__(self, \n",
    "        encoder_type: type,\n",
    "        decoder_type: type,\n",
    "        final_size: int, \n",
    "        latents: int,\n",
    "        max_envs: int,\n",
    "        atyp_min: float,\n",
    "        atyp_max: float,\n",
    "        env_optim: type,\n",
    "        env_lr: float,\n",
    "        env_epochs: int,\n",
    "        replay_batch_size: int,\n",
    "        device: str,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.latents = latents\n",
    "        self.max_envs = max_envs\n",
    "        self.final_size = final_size\n",
    "        self.atyp_min = atyp_min\n",
    "        self.atyp_max = atyp_max\n",
    "        self.device = device\n",
    "        self.encoder = encoder_type(self.latents, device=self.device)\n",
    "        self.decoder = decoder_type(self.latents, self.max_envs, device=self.device)\n",
    "        self.old_encoder = encoder_type(self.latents, device=self.device)\n",
    "        self.old_decoder = decoder_type(self.latents, self.max_envs, device=self.device)\n",
    "        self.copy_and_freeze()\n",
    "        self.encoder.to(self.device), self.decoder.to(self.device), self.old_encoder.to(self.device), self.old_decoder.to(self.device)\n",
    "        self.replay_batch_size = replay_batch_size\n",
    "        self.env_net = EnvironmentInference(self.max_envs, self.final_size)\n",
    "        self.env_net.to(self.device)\n",
    "        self.env_optim = env_optim(params=self.env_net.parameters(), lr=env_lr)\n",
    "        self.env_loss = nn.CrossEntropyLoss()\n",
    "        self.env_epochs = env_epochs\n",
    "       \n",
    "        self.m = -1\n",
    "        self.steps = 0\n",
    "        self.learning = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        self.steps += 1\n",
    "\n",
    "        x_halu, s_halu = self.sample_old()\n",
    "        \n",
    "        mu, logvar, final = self.encoder(x)\n",
    "\n",
    "        if not self.training:\n",
    "            z = mu \n",
    "            s = torch.argmax(self.env_net(final)[:, 0:self.m+1], dim=1)\n",
    "            rec_x = self.decoder(z, self.int_to_vec(s, batch_size))\n",
    "            atyp = self.get_atyp(z)\n",
    "            mu_halu_old, logvar_halu_old, final_halu_old = self.old_encoder(x_halu)\n",
    "            mu_halu, logvar_halu, final_halu = self.encoder(x_halu)\n",
    "            rec_x_halo = self.decoder(mu_halu, s_halu)\n",
    "            return rec_x, mu, logvar, x_halu, rec_x_halo, mu_halu_old, mu_halu, s_halu, atyp\n",
    "        \n",
    "        s = self.m if self.m != -1 else 0\n",
    "        z = self.reparam(mu, logvar)\n",
    "        rec_x = self.decoder(z, self.int_to_vec(s, batch_size))\n",
    "\n",
    "        atyp = self.get_atyp(z)\n",
    "\n",
    "        if self.m == -1:\n",
    "            if atyp > self.atyp_max:\n",
    "                self.m = 0\n",
    "                self.learning = True\n",
    "        \n",
    "        elif self.learning:\n",
    "            if atyp < self.atyp_min:\n",
    "                self.learning = False\n",
    "        \n",
    "        elif atyp > self.atyp_max:\n",
    "            self.learning = True\n",
    "            self.m += 1\n",
    "            if self.m > self.max_envs:\n",
    "                print(\"Warning: too many environments\")\n",
    "            self.copy_and_freeze()\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            mu_halu_old, logvar_halu_old, final_halu_old = self.old_encoder(x_halu)\n",
    "            z_halu_old = self.reparam(mu_halu_old, logvar_halu_old)\n",
    "        \n",
    "        mu_halu, logvar_halu, final_halu = self.encoder(x_halu)\n",
    "        z_halu = self.reparam(mu_halu, logvar_halu)\n",
    "        rec_x_halo = self.decoder(z_halu, s_halu)\n",
    "\n",
    "        if self.training:\n",
    "            self.train_env_network(final, s, final_halu_old, s_halu)\n",
    "\n",
    "        return rec_x, mu, logvar, x_halu, rec_x_halo, z_halu_old, z_halu, s_halu, atyp\n",
    "\n",
    "    def get_likely_env(self, final):\n",
    "        env_logits = self.env_net(final)\n",
    "        avg_env_logits = torch.mean(env_logits, dim=0)\n",
    "        valid_logits = avg_env_logits[0:self.m+1]\n",
    "        return torch.argmax(valid_logits), env_logits\n",
    "    \n",
    "    def get_atyp(self, z):\n",
    "        with torch.no_grad():\n",
    "            std, mean = torch.std_mean(z, dim=0)\n",
    "            std = std[:,None]\n",
    "            mean = mean[:, None]\n",
    "            logvar = torch.log(std.pow(2))\n",
    "            atyps = kl_div_stdnorm(mean, logvar)\n",
    "        return torch.sum(atyps)\n",
    "    \n",
    "    def reparam(self, mu, logvar):\n",
    "        eps = torch.randn(logvar.shape).to(self.device)\n",
    "        std = (0.5 * logvar).exp()\n",
    "        return mu + std * eps\n",
    "    \n",
    "    def int_to_vec(self, i, size):\n",
    "        return torch.ones([size], dtype=torch.int64).to(self.device) * i\n",
    "    \n",
    "    def copy_model(self, old_model, cur_model):\n",
    "        old_model.load_state_dict(cur_model.state_dict())\n",
    "    \n",
    "    def freeze_model(self, model):\n",
    "        disable_gradient(model)\n",
    "    \n",
    "    def copy_and_freeze(self):\n",
    "        self.copy_model(self.old_encoder, self.encoder)\n",
    "        self.freeze_model(self.old_encoder)\n",
    "        self.copy_model(self.old_decoder, self.decoder)\n",
    "        self.freeze_model(self.old_decoder)\n",
    "    \n",
    "    def train_env_network(self, final, s, final_halu_old, s_halu):\n",
    "        env_logits = self.env_net(final)\n",
    "        final_halu_old = final_halu_old[s != s_halu]\n",
    "        s_halu = s_halu[s != s_halu]\n",
    "        self.env_optim.zero_grad()\n",
    "        cur_loss = self.env_loss(env_logits, self.int_to_vec(s, env_logits.shape[0])) #don't know if dims work here\n",
    "        if len(s_halu) > 0:\n",
    "            env_logits_halu = self.env_net(final_halu_old)\n",
    "            replay_loss = self.env_loss(env_logits_halu, s_halu)\n",
    "        else: \n",
    "            replay_loss = 0\n",
    "        loss = cur_loss + replay_loss\n",
    "        loss.backward(retain_graph=True)\n",
    "        self.env_optim.step()\n",
    "    \n",
    "    def sample_old(self):\n",
    "        max_env = self.m+1 if self.m != -1 else 1\n",
    "        s = torch.randint(0, max_env, (self.replay_batch_size,)).to(self.device)\n",
    "        z = torch.randn([self.replay_batch_size, self.latents]).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            halu_x = self.old_decoder(z, s)\n",
    "        return halu_x, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, epochs, alpha, beta, optimizer, writer, steps_per_save, param_dir):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_rec_loss = 0\n",
    "        total_div_loss = 0\n",
    "        for contents in loader:\n",
    "            X = contents[0]\n",
    "            X = X.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            rec_x, mu, logvar, x_halu, rec_x_halo, z_halu_old, z_halu, s_halu, atyp = model(X)\n",
    "\n",
    "            rec_loss = torch.mean(rec_likelihood(X, rec_x))\n",
    "            kl_loss = gamma * torch.mean(torch.square(kl_div_stdnorm(mu, logvar))) #NOTE: should I square this?\n",
    "            mdl_loss = rec_loss + kl_loss\n",
    "\n",
    "            e_prox_loss = alpha * torch.mean(euclidean(z_halu, z_halu_old))\n",
    "            d_prox_loss = beta * torch.mean(rec_likelihood(x_halu, rec_x_halo)) #NOTE: not sure if this order is correct\n",
    "            dream_loss = e_prox_loss + d_prox_loss\n",
    "\n",
    "            loss = mdl_loss + dream_loss\n",
    "\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "            if model.steps % steps_per_save == 0:\n",
    "                save_model(model, os.path.join(param_dir, f\"step_{model.steps}\"))\n",
    "\n",
    "            writer.add_scalar(\"train/loss\", loss, model.steps)\n",
    "            writer.add_scalar(\"train/rec_loss\", rec_loss, model.steps)\n",
    "            writer.add_scalar(\"train/kl_loss\", kl_loss, model.steps)\n",
    "            writer.add_scalar(\"train/e_prox_loss\", e_prox_loss, model.steps)\n",
    "            writer.add_scalar(\"train/d_prox_loss\", d_prox_loss, model.steps)\n",
    "            writer.add_scalar(\"train/num_envs\", model.m+1, model.steps)\n",
    "            writer.add_scalar(\"train/atypicality\", atyp, model.steps)\n",
    "            total_loss += loss\n",
    "            total_rec_loss += rec_loss\n",
    "            total_div_loss += kl_loss\n",
    "        print(f\"epoch: {epoch}, loss={total_loss/batch_size}, rec_loss={total_rec_loss/batch_size}, total_div_loss={total_div_loss/batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_type = FCEncoder\n",
    "decoder_type = FCDecoder\n",
    "final_size = 50\n",
    "latents = 8\n",
    "max_envs = 7\n",
    "atyp_min = 0.1\n",
    "atyp_max = .7\n",
    "env_optim = torch.optim.Adam\n",
    "env_lr = 6e-4\n",
    "env_epochs = 10\n",
    "replay_batch_size = 64\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "clvae_fc = CLVAE(encoder_type, decoder_type, final_size, latents, max_envs, atyp_min, atyp_max, env_optim, env_lr, env_epochs, replay_batch_size, device)\n",
    "\n",
    "epochs=10\n",
    "lr=6e-4\n",
    "gamma=4\n",
    "alpha=1\n",
    "beta=1\n",
    "steps_per_save = 500\n",
    "optimizer = torch.optim.Adam(params=clvae_fc.parameters(), lr=lr)\n",
    "name = \"clvae_fc\" + dt.datetime.now().strftime('-%Y-%m-%d-%H-%M-%S')\n",
    "writer = SummaryWriter(os.path.join(LOG_PATH, name))\n",
    "param_dir = os.path.join(PARAM_PATH, name)\n",
    "os.mkdir(param_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(clvae_fc, sf_loader, epochs, alpha, beta, optimizer, writer, steps_per_save, param_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(clvae_fc, mnist_loader, epochs, alpha, beta, optimizer, writer, steps_per_save, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clvae_fc.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    results = clvae_fc(sf_batch)\n",
    "rec_img = results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(sf_batch[0:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(rec_img[0:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    results = clvae_fc(mnist_batch)\n",
    "rec_img = results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(mnist_batch[0:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(rec_img[0:32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifiers on Latent Space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at architecture used in vase (just linear?)\n",
    "\n",
    "define inner training loop \n",
    "define outer training loop with iterately loads trained models and logs accuracy of trained classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LatentClassifier(nn.Module):\n",
    "    def __init__(self, latents, hidden_size, n_classes):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(latents, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, n_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.linear1(x))\n",
    "        logits = self.linear2(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def train_classifier(model, train_loader, test_loader, epochs, n_classes=10, hidden_size=50, lr=1e-3):\n",
    "    model.eval()\n",
    "    classifier = LatentClassifier(latents, hidden_size, n_classes)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(params=classifier.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for X, y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            with torch.no_grad():\n",
    "                Z = model.encoder(X)[0]\n",
    "            logits = classifier(Z)\n",
    "            loss = criterion(logits, y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss\n",
    "    \n",
    "    total_acc = 0\n",
    "    size = 0\n",
    "    for x_test, y_test in test_loader:\n",
    "        size += x_test.shape[0]\n",
    "        with torch.no_grad():\n",
    "            Z = model.encoder(x_test)[0]\n",
    "            logits = classifier(Z)\n",
    "        y_hat = torch.argmax(logits, dim=1)\n",
    "        total_acc += (y_test == y_hat).sum()\n",
    "    return total_acc / size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = CommonMNIST(DATA_PATH, transform=ToTensor(), train=True, download=True)\n",
    "mnist_train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "mnist_test = CommonMNIST(DATA_PATH, transform=ToTensor(), train=False, download=True)\n",
    "mnist_test_loader =  DataLoader(mnist_test, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "fashion_train = CommonFashionMNIST(DATA_PATH, transform=ToTensor(), train=True, download=True)\n",
    "fashion_train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
    "fashion_test = CommonFashionMNIST(DATA_PATH, transform=ToTensor(), train=False, download=True)\n",
    "fashion_test_loader =  DataLoader(mnist_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train classifiers\n",
    "cl_vae = CLVAE(encoder_type, decoder_type, final_size, latents, max_envs, atyp_min, atyp_max, env_optim, env_lr, env_epochs, replay_batch_size, device)\n",
    "\n",
    "for param_path in tqdm(os.listdir(param_dir)):\n",
    "    load_model(cl_vae, os.path.join(param_dir, param_path))\n",
    "    mnist_acc = train_classifier(cl_vae, mnist_train_loader, mnist_test_loader, epochs=5, lr=1e-1)\n",
    "    fashion_acc = train_classifier(cl_vae, fashion_train_loader, fashion_test_loader, epochs=5, lr=1e-2)\n",
    "    steps = int(param_path.split(\"_\")[1])\n",
    "    writer.add_scalar(\"classifiers/mnist_acc\", mnist_acc, steps)\n",
    "    writer.add_scalar(\"classifiers/fashion_acc\", mnist_acc, steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: add a cnn model, run it, call it a day"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('lifelong_disrep')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
