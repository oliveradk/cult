{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp core.clvae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from cmaes import CMA\n",
    "import os\n",
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "from vase.core.models import FCEncoder, FCDecoder, Encoder, Decoder, EnvironmentInference\n",
    "from vase.core.utils import rec_likelihood, disable_gradient, kl_div_stdnorm, euclidean, show_batch\n",
    "from vase.config import DATA_PATH, LOG_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from vase.core.datasets.moving_mnist import CommonMNIST, CommonFashionMNIST, MovingMNIST, MovingFashionMNIST, FixedMNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "mnist_data = CommonMNIST(DATA_PATH, transform=ToTensor(), download=True)\n",
    "mnist_loader = DataLoader(mnist_data, batch_size=batch_size, shuffle=True)\n",
    "mnist_batch, _ = iter(mnist_loader).next()\n",
    "small_fashion = CommonFashionMNIST(DATA_PATH, transform=ToTensor())\n",
    "sf_loader = DataLoader(small_fashion, batch_size=batch_size, shuffle=True)\n",
    "sf_batch, _ = iter(sf_loader).next()\n",
    "fashion_data = MovingFashionMNIST(DATA_PATH, transform=ToTensor(), download=True)\n",
    "fashion_loader = DataLoader(fashion_data, batch_size, shuffle=True)\n",
    "fashion_batch, _, _ = iter(fashion_loader).next()\n",
    "mm_data = MovingMNIST(DATA_PATH, transform=ToTensor(), download=True)\n",
    "mm_loader = DataLoader(mm_data, batch_size, shuffle=True)\n",
    "mm_batch, _, _ = iter(mm_loader).next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continually Learning Variational Autoencoder\n",
    "> Performs unsupervised continual representation learning with generative replay and environment likelihood detection\n",
    "\n",
    "Notes: assumes sequential tasks - \"local stationarity\" i.e. will stay on distribution long enough to learn it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CLVAE(nn.Module):\n",
    "    def __init__(self, \n",
    "        encoder_type: type,\n",
    "        decoder_type: type,\n",
    "        final_size: int, \n",
    "        latents: int,\n",
    "        max_envs: int,\n",
    "        atyp_thresh: float,\n",
    "        env_optim: type,\n",
    "        env_lr: float,\n",
    "        env_epochs: int,\n",
    "        replay_batch_size: int,\n",
    "        device: str,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.latents = latents\n",
    "        self.max_envs = max_envs\n",
    "        self.final_size = final_size\n",
    "        self.atyp_thresh = atyp_thresh\n",
    "        self.device = device\n",
    "        self.encoder = encoder_type(self.latents, device=self.device)\n",
    "        self.decoder = decoder_type(self.latents, self.max_envs, device=self.device)\n",
    "        self.old_encoder = encoder_type(self.latents, device=self.device)\n",
    "        self.old_decoder = decoder_type(self.latents, self.max_envs, device=self.device)\n",
    "        self.copy_and_freeze()\n",
    "        self.encoder.to(self.device), self.decoder.to(self.device), self.old_encoder.to(self.device), self.old_decoder.to(self.device)\n",
    "        self.replay_batch_size = replay_batch_size\n",
    "        self.env_net = EnvironmentInference(self.max_envs, self.final_size)\n",
    "        self.env_net.to(self.device)\n",
    "        self.env_optim = env_optim(params=self.env_net.parameters(), lr=env_lr)\n",
    "        self.env_loss = nn.CrossEntropyLoss()\n",
    "        self.env_epochs = env_epochs\n",
    "       \n",
    "        self.m = -1\n",
    "        self.steps = 0\n",
    "        self.learning = False\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        self.steps += 1\n",
    "\n",
    "        x_halu, s_halu = self.sample_old()\n",
    "        \n",
    "        mu, logvar, final = self.encoder(x)\n",
    "\n",
    "        if not self.training:\n",
    "            z = mu \n",
    "            s = torch.argmax(self.env_net(final)[0:self.m+1])\n",
    "            rec_x = self.decoder(z, self.int_to_vec(s, batch_size))\n",
    "            atyp = self.get_atyp(z)\n",
    "            mu_halu_old, logvar_halu_old, final_halu_old = self.old_encoder(x_halu)\n",
    "            mu_halu, logvar_halu, final_halu = self.encoder(x_halu)\n",
    "            rec_x_halo = self.decoder(mu_halu, s_halu)\n",
    "            return rec_x, mu, logvar, x_halu, rec_x_halo, z_halu_old, z_halu, s_halu, atyp\n",
    "        \n",
    "        s = self.m if self.m != -1 else 0\n",
    "        z = self.reparam(mu, logvar)\n",
    "        rec_x = self.decoder(z, self.int_to_vec(s, batch_size))\n",
    "\n",
    "        atyp = self.get_atyp(z)\n",
    "\n",
    "        if self.m == -1:\n",
    "            if atyp > self.atyp_thresh:\n",
    "                self.m = 0\n",
    "                self.learning = True\n",
    "        \n",
    "        elif self.learning:\n",
    "            if atyp < self.atyp_thresh:\n",
    "                self.learning = False\n",
    "        \n",
    "        elif atyp > self.atyp_thresh:\n",
    "            self.learning = True\n",
    "            self.m += 1\n",
    "            self.copy_and_freeze()\n",
    "        \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            mu_halu_old, logvar_halu_old, final_halu_old = self.old_encoder(x_halu)\n",
    "            z_halu_old = self.reparam(mu_halu_old, logvar_halu_old)\n",
    "        \n",
    "        mu_halu, logvar_halu, final_halu = self.encoder(x_halu)\n",
    "        z_halu = self.reparam(mu_halu, logvar_halu)\n",
    "        rec_x_halo = self.decoder(z_halu, s_halu)\n",
    "\n",
    "        self.train_env_network(final, s, final_halu_old, s_halu)\n",
    "\n",
    "        return rec_x, mu, logvar, x_halu, rec_x_halo, z_halu_old, z_halu, s_halu, atyp\n",
    "\n",
    "    def get_likely_env(self, final):\n",
    "        env_logits = self.env_net(final)\n",
    "        avg_env_logits = torch.mean(env_logits, dim=0)\n",
    "        valid_logits = avg_env_logits[0:self.m+1]\n",
    "        return torch.argmax(valid_logits), env_logits\n",
    "    \n",
    "    def get_atyp(self, z):\n",
    "        with torch.no_grad():\n",
    "            std, mean = torch.std_mean(z, dim=0)\n",
    "            std = std[:,None]\n",
    "            mean = mean[:, None]\n",
    "            logvar = torch.log(std.pow(2))\n",
    "            atyps = kl_div_stdnorm(mean, logvar)\n",
    "        return torch.sum(atyps)\n",
    "    \n",
    "    def reparam(self, mu, logvar):\n",
    "        eps = torch.randn(logvar.shape).to(self.device)\n",
    "        std = (0.5 * logvar).exp()\n",
    "        return mu + std * eps\n",
    "    \n",
    "    def int_to_vec(self, i, size):\n",
    "        return torch.ones([size], dtype=torch.int64).to(self.device) * i\n",
    "    \n",
    "    def copy_model(self, old_model, cur_model):\n",
    "        old_model.load_state_dict(cur_model.state_dict())\n",
    "    \n",
    "    def freeze_model(self, model):\n",
    "        disable_gradient(model)\n",
    "    \n",
    "    def copy_and_freeze(self):\n",
    "        self.copy_model(self.old_encoder, self.encoder)\n",
    "        self.freeze_model(self.old_encoder)\n",
    "        self.copy_model(self.old_decoder, self.decoder)\n",
    "        self.freeze_model(self.old_decoder)\n",
    "    \n",
    "    def train_env_network(self, final, s, final_halu_old, s_halu):\n",
    "        env_logits = self.env_net(final)\n",
    "        final_halu_old = final_halu_old[s != s_halu]\n",
    "        s_halu = s_halu[s != s_halu]\n",
    "        self.env_optim.zero_grad()\n",
    "        cur_loss = self.env_loss(env_logits, self.int_to_vec(s, env_logits.shape[0])) #don't know if dims work here\n",
    "        if len(s_halu) > 0:\n",
    "            env_logits_halu = self.env_net(final_halu_old)\n",
    "            replay_loss = self.env_loss(env_logits_halu, s_halu)\n",
    "        else: \n",
    "            replay_loss = 0\n",
    "        loss = cur_loss + replay_loss\n",
    "        loss.backward(retain_graph=True)\n",
    "        self.env_optim.step()\n",
    "    \n",
    "    def sample_old(self):\n",
    "        max_env = self.m+1 if self.m != -1 else 1\n",
    "        s = torch.randint(0, max_env, (self.replay_batch_size,)).to(self.device)\n",
    "        z = torch.randn([self.replay_batch_size, self.latents]).to(self.device)\n",
    "        with torch.no_grad():\n",
    "            halu_x = self.old_decoder(z, s)\n",
    "        return halu_x, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, epochs, alpha, beta, optimizer, writer):\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_rec_loss = 0\n",
    "        total_div_loss = 0\n",
    "        for contents in loader:\n",
    "            X = contents[0]\n",
    "            X = X.to(device)\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            rec_x, mu, logvar, x_halu, rec_x_halo, z_halu_old, z_halu, s_halu, atyp = model(X)\n",
    "\n",
    "            rec_loss = torch.mean(rec_likelihood(X, rec_x))\n",
    "            kl_loss = gamma * torch.mean(torch.square(kl_div_stdnorm(mu, logvar))) #NOTE: should I square this?\n",
    "            mdl_loss = rec_loss + kl_loss\n",
    "\n",
    "            e_prox_loss = alpha * torch.mean(euclidean(z_halu, z_halu_old))\n",
    "            d_prox_loss = beta * torch.mean(rec_likelihood(x_halu, rec_x_halo)) #NOTE: not sure if this order is correct\n",
    "            dream_loss = e_prox_loss + d_prox_loss\n",
    "\n",
    "            loss = mdl_loss + dream_loss\n",
    "\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "            writer.add_scalar(\"train/loss\", loss, model.steps)\n",
    "            writer.add_scalar(\"train/rec_loss\", rec_loss, model.steps)\n",
    "            writer.add_scalar(\"train/kl_loss\", kl_loss, model.steps)\n",
    "            writer.add_scalar(\"train/e_prox_loss\", e_prox_loss, model.steps)\n",
    "            writer.add_scalar(\"train/d_prox_loss\", d_prox_loss, model.steps)\n",
    "            writer.add_scalar(\"train/num_envs\", model.m+1, model.steps)\n",
    "            writer.add_scalar(\"train/atypicality\", atyp, model.steps)\n",
    "            total_loss += loss\n",
    "            total_rec_loss += rec_loss\n",
    "            total_div_loss += kl_loss\n",
    "        print(f\"epoch: {epoch}, loss={total_loss/batch_size}, rec_loss={total_rec_loss/batch_size}, total_div_loss={total_div_loss/batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_type = FCEncoder\n",
    "decoder_type = FCDecoder\n",
    "final_size = 50\n",
    "latents = 8\n",
    "max_envs = 7\n",
    "atyp_thresh = .5\n",
    "env_optim = torch.optim.Adam\n",
    "env_lr = 6e-4\n",
    "env_epochs = 10\n",
    "replay_batch_size = 64\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "clvae_fc = CLVAE(encoder_type, decoder_type, final_size, latents, max_envs, atyp_thresh, env_optim, env_lr, env_epochs, replay_batch_size, device)\n",
    "\n",
    "epochs=10\n",
    "lr=6e-4\n",
    "gamma=20\n",
    "alpha=1\n",
    "beta=10\n",
    "optimizer = torch.optim.Adam(params=clvae_fc.parameters(), lr=lr)\n",
    "name = \"clvae_fc\" + dt.datetime.now().strftime('-%Y-%m-%d-%H-%M-%S')\n",
    "writer = SummaryWriter(os.path.join(LOG_PATH, name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Class values must be smaller than num_classes.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb#ch0000014?line=0'>1</a>\u001b[0m train(clvae_fc, sf_loader, epochs, alpha, beta, optimizer, writer)\n",
      "\u001b[1;32m/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb Cell 10'\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, loader, epochs, alpha, beta, optimizer, writer)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb#ch0000015?line=7'>8</a>\u001b[0m X \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb#ch0000015?line=8'>9</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb#ch0000015?line=10'>11</a>\u001b[0m rec_x, mu, logvar, x_halu, rec_x_halo, z_halu_old, z_halu, s_halu, atyp \u001b[39m=\u001b[39m model(X)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb#ch0000015?line=12'>13</a>\u001b[0m rec_loss \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmean(rec_likelihood(X, rec_x))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb#ch0000015?line=13'>14</a>\u001b[0m kl_loss \u001b[39m=\u001b[39m gamma \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mmean(torch\u001b[39m.\u001b[39msquare(kl_div_stdnorm(mu, logvar))) \u001b[39m#NOTE: should I square this?\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/lifelong_disrep/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/lifelong_disrep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/lifelong_disrep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/lifelong_disrep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/lifelong_disrep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/lifelong_disrep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/lifelong_disrep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/lifelong_disrep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "\u001b[1;32m/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb Cell 9'\u001b[0m in \u001b[0;36mCLVAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb#ch0000011?line=39'>40</a>\u001b[0m batch_size \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb#ch0000011?line=40'>41</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb#ch0000011?line=42'>43</a>\u001b[0m x_halu, s_halu \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msample_old()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb#ch0000011?line=44'>45</a>\u001b[0m mu, logvar, final \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoder(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb#ch0000011?line=46'>47</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining:\n",
      "\u001b[1;32m/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb Cell 9'\u001b[0m in \u001b[0;36mCLVAE.sample_old\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb#ch0000011?line=142'>143</a>\u001b[0m z \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandn([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplay_batch_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlatents])\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb#ch0000011?line=143'>144</a>\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb#ch0000011?line=144'>145</a>\u001b[0m     halu_x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mold_decoder(z, s)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/02c_core.clvae.ipynb#ch0000011?line=145'>146</a>\u001b[0m \u001b[39mreturn\u001b[39;00m halu_x, s\n",
      "File \u001b[0;32m~/miniforge3/envs/lifelong_disrep/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/lifelong_disrep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1105'>1106</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/lifelong_disrep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1106'>1107</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/lifelong_disrep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1107'>1108</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/lifelong_disrep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1108'>1109</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/lifelong_disrep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1109'>1110</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/lifelong_disrep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1110'>1111</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/oliverdaniels-koch/miniforge3/envs/lifelong_disrep/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1111'>1112</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/NotebookProjects/lifelong_disrep/vase/core/models.py:153\u001b[0m, in \u001b[0;36mFCDecoder.forward\u001b[0;34m(self, z, s)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/vase/core/models.py?line=141'>142</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/vase/core/models.py?line=142'>143</a>\u001b[0m \u001b[39mDecode the latent and environmental variables\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/vase/core/models.py?line=143'>144</a>\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/vase/core/models.py?line=149'>150</a>\u001b[0m \u001b[39m    Means for (batchsize, widgt, height) Bernoulli's (which can be interpreted as the reconstructed image)\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/vase/core/models.py?line=150'>151</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/vase/core/models.py?line=151'>152</a>\u001b[0m \u001b[39mif\u001b[39;00m s \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/vase/core/models.py?line=152'>153</a>\u001b[0m     s_one_hot \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mone_hot(s, num_classes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_envs)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n\u001b[1;32m    <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/vase/core/models.py?line=153'>154</a>\u001b[0m     z \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((z, s_one_hot), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    <a href='file:///Users/oliverdaniels-koch/NotebookProjects/lifelong_disrep/vase/core/models.py?line=154'>155</a>\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlinear1(z))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Class values must be smaller than num_classes."
     ]
    }
   ],
   "source": [
    "train(clvae_fc, sf_loader, epochs, alpha, beta, optimizer, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss=82291.953125, rec_loss=2983.999755859375, total_div_loss=62.65172576904297\n",
      "epoch: 1, loss=82214.171875, rec_loss=2909.527587890625, total_div_loss=61.54328155517578\n",
      "epoch: 2, loss=82199.28125, rec_loss=2897.67236328125, total_div_loss=65.13917541503906\n",
      "epoch: 3, loss=82181.3984375, rec_loss=2888.50830078125, total_div_loss=67.56062316894531\n",
      "epoch: 4, loss=82173.90625, rec_loss=2885.269287109375, total_div_loss=68.66284942626953\n",
      "epoch: 5, loss=82165.140625, rec_loss=2879.69970703125, total_div_loss=70.47335815429688\n",
      "epoch: 6, loss=82161.03125, rec_loss=2878.7900390625, total_div_loss=71.29312896728516\n",
      "epoch: 7, loss=82157.9296875, rec_loss=2876.942138671875, total_div_loss=71.86474609375\n",
      "epoch: 8, loss=82154.1875, rec_loss=2875.462890625, total_div_loss=71.8026123046875\n",
      "epoch: 9, loss=82150.3046875, rec_loss=2873.46240234375, total_div_loss=72.2280044555664\n"
     ]
    }
   ],
   "source": [
    "train(clvae_fc, mnist_loader, epochs, alpha, beta, optimizer, writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('lifelong_disrep')",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
