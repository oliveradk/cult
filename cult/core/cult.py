# AUTOGENERATED! DO NOT EDIT! File to edit: 02b_core.cult.ipynb (unless otherwise specified).

__all__ = ['CULT', 'LatentClassifier', 'CULTTrainer']

# Cell
import torch
from torch import nn
from torch.utils.tensorboard import SummaryWriter
import os
import numpy as np
import copy
from tqdm import tqdm

from .models import FCEncoder, FCDecoder, CNNEncoder, CNNDecoder, EnvironmentInference
from .utils import rec_likelihood, disable_gradient, kl_div_stdnorm, euclidean, show_batch, save_model, load_model
from ..config import DATA_PATH, LOG_PATH, PARAM_PATH

# Cell
class CULT(nn.Module):
    def __init__(self,
        encoder_type: type,
        decoder_type: type,
        final_size: int,
        latents: int,
        max_envs: int,
        atyp_min: float,
        atyp_max: float,
        env_optim: type,
        env_lr: float,
        env_epochs: int,
        replay_batch_size: int,
        device: str,
        steps_per_reset: int=None,
    ):
        super().__init__()
        self.latents = latents
        self.max_envs = max_envs
        self.final_size = final_size
        self.atyp_min = atyp_min
        self.atyp_max = atyp_max
        self.device = device
        self.encoder = encoder_type(self.latents, device=self.device)
        self.decoder = decoder_type(self.latents, self.max_envs, device=self.device)
        self.old_encoder = encoder_type(self.latents, device=self.device)
        self.old_decoder = decoder_type(self.latents, self.max_envs, device=self.device)
        self.copy_and_freeze()
        self.encoder.to(self.device), self.decoder.to(self.device), self.old_encoder.to(self.device), self.old_decoder.to(self.device)
        self.replay_batch_size = replay_batch_size
        self.env_lr = env_lr
        self.env_optim_type = env_optim
        self.reset_env_net()
        self.env_loss = nn.CrossEntropyLoss()
        self.env_epochs = env_epochs
        self.steps_per_reset = steps_per_reset

        self.m = -1
        self.steps = 0
        self.learning = False

    def forward(self, x):
        batch_size = x.shape[0]
        self.steps += 1

        x_halu, s_halu = self.sample_old()

        mu, logvar, final = self.encoder(x)

        if not self.training:
            z = mu
            s = torch.argmax(self.env_net(final)[:, 0:self.m+1], dim=1)
            rec_x = self.decoder(z, self.int_to_vec(s, batch_size))
            atyp = self.get_atyp(z)
            mu_halu_old, logvar_halu_old, final_halu_old = self.old_encoder(x_halu)
            mu_halu, logvar_halu, final_halu = self.encoder(x_halu)
            rec_x_halo = self.decoder(mu_halu, s_halu)
            return rec_x, mu, logvar, x_halu, rec_x_halo, mu_halu_old, mu_halu, s_halu, atyp

        s = self.m if self.m != -1 else 0
        z = self.reparam(mu, logvar)
        rec_x = self.decoder(z, self.int_to_vec(s, batch_size))

        atyp = self.get_atyp(z)

        if self.m == -1:
            if atyp > self.atyp_max:
                self.m = 0
                self.learning = True

        elif self.learning:
            if atyp < self.atyp_min:
                self.learning = False

        elif atyp > self.atyp_max:
            self.learning = True
            self.m += 1
            if self.m > self.max_envs:
                print("Warning: too many environments")
            if self.steps_per_reset is None:
                self.copy_and_freeze()
                self.reset_env_net()

        if self.steps_per_reset is not None and self.steps % self.steps_per_reset == 0:
            self.copy_and_freeze()
            self.reset_env_net()


        with torch.no_grad():
            mu_halu_old, logvar_halu_old, final_halu_old = self.old_encoder(x_halu)
            z_halu_old = self.reparam(mu_halu_old, logvar_halu_old)

        mu_halu, logvar_halu, final_halu = self.encoder(x_halu)
        z_halu = self.reparam(mu_halu, logvar_halu)
        rec_x_halo = self.decoder(z_halu, s_halu)

        avg_env_loss, env_acc = self.train_env_network(final, s, final_halu_old, s_halu) if self.training else 0

        return rec_x, mu, logvar, x_halu, rec_x_halo, z_halu_old, z_halu, s_halu, atyp, avg_env_loss, env_acc

    def get_likely_env(self, final):
        env_logits = self.env_net(final)
        avg_env_logits = torch.mean(env_logits, dim=0)
        valid_logits = avg_env_logits[0:self.m+1]
        return torch.argmax(valid_logits), env_logits

    def get_atyp(self, z):
        with torch.no_grad():
            std, mean = torch.std_mean(z, dim=0)
            std = std[:,None]
            mean = mean[:, None]
            logvar = torch.log(std.pow(2))
            atyps = kl_div_stdnorm(mean, logvar)
        return torch.sum(atyps)

    def reparam(self, mu, logvar):
        eps = torch.randn(logvar.shape).to(self.device)
        std = (0.5 * logvar).exp()
        return mu + std * eps

    def int_to_vec(self, i, size):
        return torch.ones([size], dtype=torch.int64).to(self.device) * i

    def copy_model(self, old_model, cur_model):
        old_model.load_state_dict(cur_model.state_dict())

    def freeze_model(self, model):
        disable_gradient(model)

    def copy_and_freeze(self):
        self.copy_model(self.old_encoder, self.encoder)
        self.freeze_model(self.old_encoder)
        self.copy_model(self.old_decoder, self.decoder)
        self.freeze_model(self.old_decoder)

    def train_env_network(self, final, s, final_halu_old, s_halu):
        total_env_loss = 0
        total_acc = 0
        total_logits = 0
        for epoch in range(self.env_epochs):
            self.env_optim.zero_grad()
            env_logits = self.env_net(final)
            final_halu_old = final_halu_old[s != s_halu]
            s_halu = s_halu[s != s_halu]
            cur_loss = self.env_loss(env_logits, self.int_to_vec(s, env_logits.shape[0])) #don't know if dims work here
            if len(s_halu) > 0:
                env_logits_halu = self.env_net(final_halu_old)
                replay_loss = self.env_loss(env_logits_halu, s_halu)
            else:
                replay_loss = 0
            loss = cur_loss + 2 * replay_loss #TODO: set as hyperparam
            loss.backward(retain_graph=True)
            total_env_loss += loss
            self.env_optim.step()
            env_accc = (torch.argmax(env_logits, dim=1) == s).sum()
            halu_acc = (torch.argmax(env_logits_halu) == s_halu).sum() if len(s_halu) > 0 else 0
            total_acc += env_accc + halu_acc
            total_logits += env_logits.shape[0] + env_logits_halu.shape[0] if len(s_halu) > 0 else env_logits.shape[0]
        return total_env_loss / self.env_epochs, total_acc / total_logits

    def reset_env_net(self):
        self.env_net = EnvironmentInference(self.max_envs, self.final_size)
        self.env_optim = self.env_optim_type(params=self.env_net.parameters(), lr=self.env_lr, weight_decay=1e-1)
        self.env_net.to(self.device)

    def sample_old(self):
        max_env = self.m+1 if self.m != -1 else 1
        s = torch.randint(0, max_env, (self.replay_batch_size,)).to(self.device)
        z = torch.randn([self.replay_batch_size, self.latents]).to(self.device)
        with torch.no_grad():
            halu_x = self.old_decoder(z, s)
        return halu_x, s

# Cell
class LatentClassifier(nn.Module):
    def __init__(self, latents, hidden_size, n_classes):
        super().__init__()
        self.linear1 = nn.Linear(latents, hidden_size)
        self.linear2 = nn.Linear(hidden_size, n_classes)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.relu(self.linear1(x))
        logits = self.linear2(x)
        return logits

# Cell
class CULTTrainer():
    def __init__(self,
        name: str,
        optim_type: type,
        lr: float,
        kl_scale: float,
        e_prox_scale: float,
        d_prox_scale: float,
        encoder_type: type,
        decoder_type: type,
        final_size: int,
        latents: int,
        max_envs: int,
        atyp_min: float,
        atyp_max: float,
        env_optim: type,
        env_lr: float,
        env_epochs: int,
        replay_batch_size: int,
        steps_per_save: int,
        device: str,
        steps_per_reset: int=None
    ):
        self.name = name
        self.device = device
        self.model = CULT(encoder_type, decoder_type, final_size, latents, max_envs, atyp_min, atyp_max, env_optim, env_lr, env_epochs, replay_batch_size, device, steps_per_reset)
        self.snap_model = CULT(encoder_type, decoder_type, final_size, latents, max_envs, atyp_min, atyp_max, env_optim, env_lr, env_epochs, replay_batch_size, device, steps_per_reset)
        #TODO: add toggle for step based gen model update
        self.optimizer = optim_type(params=self.model.parameters(), lr=lr)
        self.kl_scale = kl_scale
        self.e_prox_scale = e_prox_scale
        self.d_prox_scale = d_prox_scale
        self.steps_per_save = steps_per_save
        self.writer = SummaryWriter(os.path.join(LOG_PATH, name))
        self.param_dir = os.path.join(PARAM_PATH, name)
        if not os.path.isdir(self.param_dir):
            os.mkdir(self.param_dir)

    def train(self, loader, epochs, test_batches, verbose=True):
        for epoch in range(epochs):
            total_loss = 0
            total_rec_loss = 0
            total_div_loss = 0
            for contents in loader:
                X = contents[0]
                X = X.to(self.device)
                self.optimizer.zero_grad()

                rec_x, mu, logvar, x_halu, rec_x_halo, z_halu_old, z_halu, s_halu, atyp, avg_env_loss, env_acc = self.model(X)

                rec_loss = torch.mean(rec_likelihood(X, rec_x))
                kl_loss = self.kl_scale * torch.mean(torch.square(kl_div_stdnorm(mu, logvar))) #NOTE: should I square this?
                mdl_loss = rec_loss + kl_loss

                e_prox_loss = self.e_prox_scale * torch.mean(euclidean(z_halu, z_halu_old))
                d_prox_loss = self.d_prox_scale * torch.mean(rec_likelihood(x_halu, rec_x_halo)) #NOTE: not sure if this order is correct

                dream_loss = e_prox_loss + d_prox_loss

                loss = mdl_loss + dream_loss

                loss.backward(retain_graph=True)
                self.optimizer.step()

                if self.model.steps % self.steps_per_save == 0:
                    save_model(self.model, os.path.join(self.param_dir, f"step_{self.model.steps}"))

                self.writer.add_scalar("train/loss", loss, self.model.steps)
                self.writer.add_scalar("train/rec_loss", rec_loss, self.model.steps)
                self.writer.add_scalar("train/kl_loss", kl_loss, self.model.steps)
                self.writer.add_scalar("train/e_prox_loss", e_prox_loss, self.model.steps)
                self.writer.add_scalar("train/d_prox_loss", d_prox_loss, self.model.steps)
                self.writer.add_scalar("train/num_envs", self.model.m+1, self.model.steps)
                self.writer.add_scalar("train/atypicality", atyp, self.model.steps)
                self.writer.add_scalar("train/avg_env_loss", avg_env_loss, self.model.steps)
                self.writer.add_scalar("train/avg_env_acc", env_acc, self.model.steps)
                for i in range(self.model.m+1):
                    if i+1 > len(test_batches):
                        break
                    acc = self._env_accuracy(test_batches[i], i)
                    self.writer.add_scalar(f"train/env_{i}_acc", acc, self.model.steps)
                total_loss += loss
                total_rec_loss += rec_loss
                total_div_loss += kl_loss
            if verbose:
                print(f"epoch: {epoch}, loss={total_loss/len(loader)}, rec_loss={total_rec_loss/len(loader)}, total_div_loss={total_div_loss/len(loader)}")


    def train_latent_classifiers(self, train_loaders, test_loaders, names, n_classes_list, epochs=10, hidden_size=50, lr=1e-3, verbose=True): #TODO: allow for simultaneous training on n datasets
        for param_path in tqdm(sorted(os.listdir(self.param_dir), key=lambda name: int(name.split("_")[1]))):
            load_model(self.snap_model, os.path.join(self.param_dir, param_path))
            steps = int(param_path.split("_")[1])
            n_classifiers = len(train_loaders)
            for i in range(n_classifiers):
                acc = self.train_latent_classifier(train_loaders[i], test_loaders[i], epochs, n_classes_list[i], hidden_size, lr=lr, verbose=verbose)
                self.writer.add_scalar(f"classifiers/{names[i]}", acc, steps)


    def train_latent_classifier(self, train_loader, test_loader, epochs, n_classes=10, hidden_size=50, lr=1e-3, verbose=True):
        self.snap_model.eval()
        classifier = LatentClassifier(self.snap_model.latents, hidden_size, n_classes)
        criterion = nn.CrossEntropyLoss()
        optimizer = torch.optim.Adam(params=classifier.parameters(), lr=lr)
        for epoch in range(epochs):
            total_loss = 0
            for X, y in train_loader:
                optimizer.zero_grad()
                with torch.no_grad():
                    Z = self.snap_model.encoder(X)[0]
                logits = classifier(Z)
                loss = criterion(logits, y)
                loss.backward()
                optimizer.step()
                total_loss += loss
            if verbose:
                print("epoch", epoch, "acc", self._accuracy(self.snap_model, classifier,test_loader))

        return self._accuracy(self.snap_model, classifier, test_loader)

    def _accuracy(self, model, classifier, test_loader):
        total_acc = 0
        size = 0
        for x_test, y_test in test_loader:
            size += x_test.shape[0]
            with torch.no_grad():
                Z = model.encoder(x_test)[0]
                logits = classifier(Z)
            y_hat = torch.argmax(logits, dim=1)
            total_acc += (y_test == y_hat).sum()
        return total_acc / size

    def _env_accuracy(self, batch, label):
        total_acc = 0
        size = 0
        with torch.no_grad():
            _, _, final = self.model.encoder(batch)
            logits = self.model.env_net(final)
            acc = (torch.argmax(logits, dim=1) == label).sum()
            total_acc += acc
            size += logits.shape[0]
        return total_acc / size

    def env_accuracy(self, loader, label):
        total_acc = 0
        size = 0
        for X, _ in loader:
            with torch.no_grad():
                _, _, final = self.model.encoder(X)
                logits = self.model.env_net(final)
                acc = (torch.argmax(logits, dim=1) == label).sum()
                total_acc += acc
                size += logits.shape[0]
        return total_acc / size

    def rec_loss(self, test_loader):
        total_rec_loss = 0
        data_size = 0
        for X, _ in test_loader:
            with torch.no_grad():
                model_out = self.model(X)
                rec_X = model_out[0]
                rec_loss = rec_likelihood(X, rec_X).sum()
                total_rec_loss += rec_loss
                data_size += X.shape[0]
        return total_rec_loss / data_size