# AUTOGENERATED! DO NOT EDIT! File to edit: 02a_core.models.ipynb (unless otherwise specified).

__all__ = ['Encoder', 'FCEncoder', 'EnvironmentInference', 'env_dist_to_idx', 'Decoder', 'FCDecoder', 'reparam',
           'VanillaVAE', 'PaperVanillaVAE', 'FCVAE', 'latent_mask', 'apply_mask', 'LatentMaskVAE', 'EnvInferVAE',
           'generate_samples', 'GenReplayVAE']

# Cell
import torch
from torch import nn
from torch.nn import functional as F
import numpy as np

from ..config import DATA_PATH
from .utils import rec_likelihood, kl_div_stdnorm

# Cell
class Encoder(nn.Module):
    def __init__(self, latents=10):
        super().__init__()
        self.latents = latents
        #NOTE: no pooling? should compare results with and without
        self.conv1 = nn.Conv2d(1, 64, (4,4), stride=2, padding=1)
        self.conv2 = nn.Conv2d(64, 64, (4,4), 2, padding=1)
        self.conv3 = nn.Conv2d(64, 128, (4,4), 2, padding=1)
        self.conv4 = nn.Conv2d(128, 128, (4,4), 2, padding=1)
        self.linear = nn.Linear(2048, 256)
        self.linear_mu = nn.Linear(256, self.latents)
        self.linear_logvar = nn.Linear(256, self.latents)
        self.relu = nn.ReLU()

    def forward(self, x):
        """
        Returns mean and standard deviation to parameterize sigmoid,
        and final layer to compute environment
        """
        x = self.relu(self.conv1(x)) # (batch_size, 64, 32, 32)
        x = self.relu(self.conv2(x)) # (batch_size, 64, 16, 16)
        x = self.relu(self.conv3(x)) # (batch_size, 128, 8, 8)
        x = self.relu(self.conv4(x)) # (batch_size, 128, 4, 4)
        x = x.reshape(-1, 2048)
        final = self.relu(self.linear(x))
        mu = self.linear_mu(final)
        logvar = self.linear_logvar(final)
        return mu, logvar, final.detach() #detach to prevent gradient flow

# Cell
class FCEncoder(nn.Module):
    def __init__(self, latents: int):
        super().__init__()
        self.latents = latents
        self.latents = latents
        self.linear1 = nn.Linear(784, 50)
        self.linear_mu = nn.Linear(50, latents)
        self.linear_logvar = nn.Linear(50, latents)
        self.act = nn.ReLU()

    def forward(self, x):
        x = x.reshape(-1, 784)
        final = self.act(self.linear1(x))
        mu = self.linear_mu(final)
        logvar = self.linear_logvar(final) #TODO: should this be exponentiated?
        return mu, logvar, final

# Cell
class EnvironmentInference(nn.Module):
    def __init__(self, max_environmnets: int, input_dim:int):
        super().__init__()
        self.max_environments = max_environmnets
        self.input_dim = input_dim
        self.linear = nn.Linear(input_dim, max_environmnets)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, final_latent):
        x = self.linear(final_latent)
        return self.softmax(x)

# Cell
def env_dist_to_idx(env_dist: torch.Tensor, max_environments: int) -> torch.Tensor:
    """Converts a batch of distributions to a one-hot vector"""
    batch_size = env_dist.shape[0]
    avg_env_dist = env_dist.mean(dim=0)
    env_idx = torch.argmax(avg_env_dist)
    return torch.ones((batch_size), dtype=torch.int64) * env_idx


# Cell
class Decoder(nn.Module):
    def __init__(self, latents:int, max_envs=0):
        super().__init__()
        self.max_envs = max_envs
        self.latents = latents
        self.linear2 = nn.Linear(latents + max_envs, 256)
        self.linear1 = nn.Linear(256, 2048)
        self.conv4 = nn.ConvTranspose2d(128, 128, (4,4), 2, padding=1)
        self.conv3 = nn.ConvTranspose2d(128, 64, (4,4), 2, padding=1)
        self.conv2 = nn.ConvTranspose2d(64, 64, (4,4), 2, padding=1)
        self.conv1 = nn.ConvTranspose2d(64, 1, (4,4), 2, padding=1)
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()

    def forward(self, z, s=None):
        """
        Decode the latent and environmental variables

        Args:
            z (Tensor): latent variables
            s (Tensor): environment indicies (not one hot)

        Returns:
            Means for (batchsize, widgt, height) Bernoulli's (which can be interpreted as the reconstructed image)
        """

        if s is not None:
            s_one_hot = F.one_hot(s, num_classes=self.max_envs)
            z = torch.cat((z, s_one_hot), dim=1)
        x = self.relu(self.linear2(z)) # (batch_size, 256)
        x = self.relu(self.linear1(x)) # (batch_size, 512)
        x = x.reshape(-1, 128, 4, 4) # (batch_size, 128, 2, 2)
        x = self.relu(self.conv4(x)) # (batch_size, 128, 6, 6)
        x = self.relu(self.conv3(x)) # (batch_size, 64, 14, 14)
        x = self.relu(self.conv2(x)) # (batch_size, 64, 30, 30) WRONG (should be 31)
        out = self.sigmoid(self.conv1(x))
        return out

# Cell
class FCDecoder(nn.Module):
    def __init__(self, latents: int, max_envs=0):
        super().__init__()
        self.max_envs = max_envs
        self.latents = latents
        self.linear1 = nn.Linear(latents + max_envs, 50)
        self.linear2 = nn.Linear(50, 784)
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()

    def forward(self, z, s=None):
        """
        Decode the latent and environmental variables

        Args:
            z (Tensor): latent variables
            s (Tensor): one-hot encoded environmental variable (not sure how this works...)

        Returns:
            Means for (batchsize, widgt, height) Bernoulli's (which can be interpreted as the reconstructed image)
        """
        if s is not None:
            s_one_hot = F.one_hot(s, num_classes=self.max_envs)
            z = torch.cat((z, s_one_hot), dim=1)
        x = self.relu(self.linear1(z))
        x = self.linear2(x)
        out = self.sigmoid(x)
        out = out.reshape(-1, 1, 28, 28)
        return out

# Cell
def reparam(mu, logvar, device='cpu'):
    eps = torch.randn(logvar.shape).to(device)
    std = (0.5 * logvar).exp()
    return mu + std * eps

# Cell
class VanillaVAE(nn.Module):
    def __init__(self, encoder: type, decoder: type, latents: int, device: str):
        super().__init__()
        self.encoder = encoder(latents=latents)
        self.decoder = decoder(latents=latents)
        self.device = device

    def forward(self, x):
        mu, logvar, _final = self.encoder(x)
        if self.training:
            z = reparam(mu, logvar, device=self.device)
        else:
            z = mu
        rec_img = self.decoder(z=z)
        return rec_img, mu, logvar

# Cell
class PaperVanillaVAE(VanillaVAE):
    def __init__(self, latents: int, device:str):
        super().__init__(encoder=Encoder, decoder=Decoder, latents=latents, device=device)

# Cell
class FCVAE(VanillaVAE):
    def __init__(self, latents: int, device='cpu'):
        super().__init__(encoder=FCEncoder, decoder=FCDecoder, latents=latents, device=device)


# Cell
def latent_mask(z, lam, lam_1=1e-4, lam_2=.85):
    std, mean = torch.std_mean(z, dim=0)
    std = std[:,None]
    mean = mean[:, None]
    logvar = torch.log(std.pow(2))
    alphas = kl_div_stdnorm(mean, logvar)
    alphas[alphas < lam_1] = 0
    alphas[alphas > lam_2] = 1
    a = alphas < lam
    return a

# Cell
def apply_mask(a, z):
    masked_z = torch.clone(z)
    masked_z[:, ~a] = 0
    return masked_z

# Cell
class LatentMaskVAE(VanillaVAE):
    def __init__(self, encoder: type, decoder: type, latents: int, device: str, lam: float):
        self.lam = lam
        super().__init__(encoder, decoder, latents, device)

    def forward(self, x):
        mu, logvar, _final = self.encoder(x)
        if self.training:
            z = reparam(mu, logvar, device=self.device)
        else:
            z = mu

        #latent masking
        a = latent_mask(z, self.lam)
        masked_z = apply_mask(a, z)

        rec_img = self.decoder(z=masked_z)
        return rec_img, mu, logvar

# Cell
class EnvInferVAE(nn.Module):
    def __init__(self, encoder: type, decoder: type, latents: int, max_envs: int, lam: float, kappa: float, device: str):
        super().__init__()
        self.latents = latents
        self.m = 0
        self.max_envs = max_envs
        self.lam = lam
        self.kappa = kappa
        self.env_count = [0] * self.max_envs
        self.rec_loss_avgs = []
        self.latent_masks = []
        self.used_masks = []
        self.encoder = encoder(latents=latents)
        self.decoder = decoder(latents=latents, max_envs=max_envs)
        self.device = device

    def forward(self, x):
        batch_size = x.shape[0]
        mu, logvar, _final = self.encoder(x)
        if self.training:
            z = reparam(mu, logvar, device=self.device)
        else:
            z = mu

        #latent masking
        a = latent_mask(z, self.lam)
        masked_z = apply_mask(a, z)

        #infer environment
        env_idx = self.infer_env(x, z, a, masked_z)
        s = torch.ones(batch_size, dtype=torch.int64) * env_idx

        rec_img = self.decoder(z=masked_z, s=s)
        return rec_img, mu, logvar, env_idx, z

    def infer_env(self, x, z, a, masked_z):
        # u = model.used(z)
        batch_size = x.shape[0]

        #get maximum likelihood environment using "analysis by synthesis"
        losses = []
        for s_i in range(self.m+1):
            s = torch.ones(batch_size, dtype=torch.int64) * s_i
            with torch.no_grad():
                x_rec = self.decoder(masked_z, s)
                losses.append(torch.sum(rec_likelihood(x, x_rec)))
        env_idx = torch.argmin(torch.tensor(losses))

        rec_loss = losses[env_idx]
        avg_rec_loss = rec_loss / batch_size

        if self.env_count[0] == 0:
            self.env_count[self.m] += batch_size
            self.latent_masks.append(a)
            self.rec_loss_avgs.append(avg_rec_loss)
            return self.m
        elif (avg_rec_loss > self.kappa * self.rec_loss_avgs[env_idx] or not torch.equal(a, self.latent_masks[env_idx])) and self.m < self.max_envs-1:
            if avg_rec_loss > self.kappa * self.rec_loss_avgs[env_idx]:
                print("New environment: anomolous reconstruction loss")
            else:
                print("New environment: latent masks did not match")
            self.m += 1
            self.env_count[self.m] += batch_size
            self.latent_masks.append(a)
            self.rec_loss_avgs.append(avg_rec_loss)
            return self.m
        else:
            #TODO add warning about exceeding max envs or something
            self.env_count[env_idx] += batch_size
            n = self.env_count[env_idx]
            m = batch_size
            self.rec_loss_avgs[env_idx] = self.rec_loss_avgs[env_idx] * ((n-m)/n) + rec_loss/n #cumulative average
            return env_idx

# Cell
def generate_samples(vae: EnvInferVAE, batch_size: int):
    z = torch.randn(size=(batch_size, vae.latents))
    s = torch.randint(0, vae.m+1, (batch_size,))
    x_sample = vae.decoder(z, s)
    return x_sample

# Cell
class GenReplayVAE(nn.Module):
    def __init__(self, encoder: type, decoder: type, latents: int, max_envs: int, lam: float, kappa: float, tau: int, device: str):
        super().__init__()
        self.tau = tau
        self.model = EnvInferVAE(encoder, decoder, latents, max_envs, lam, kappa, device)
        self.old_model = EnvInferVAE(encoder, decoder, latents, max_envs, lam, kappa, device)
        self.old_model.train(False) #freezes old model
        self.steps = 0

    def forward(self, x):
        return self.model(x)

    def sample(self, batch_size, increment=True):
        if increment:
            self.steps +=1
        if self.steps % self.tau == 0:
            self.old_model.load_state_dict(self.model.state_dict())
        samples = generate_samples(self.old_model, batch_size)
        return samples

    def forward_halu(self, x):
        rec_X, _mu, _logvar, _env_idx, z = self.model(x)
        old_rec_X, _old_mu, _old_logvar, _old_env_idx, old_z = self.old_model(x)
        return rec_X, old_rec_X, z, old_z

