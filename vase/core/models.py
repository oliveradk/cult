# AUTOGENERATED! DO NOT EDIT! File to edit: 02a_core.models.ipynb (unless otherwise specified).

__all__ = ['Encoder', 'EnvironmentInference', 'env_dist_to_one_hot']

# Cell
import torch
from torch import nn
from torch.nn import functional as F

from ..config import DATA_PATH

# Cell
class Encoder(nn.Module):
    def __init__(self, latents=10):
        super().__init__()
        self.latents = latents
        #NOTE: no pooling? should compare results with and without
        self.conv1 = nn.Conv2d(1, 64, (4,4), stride=2, padding=1)
        self.conv2 = nn.Conv2d(64, 64, (4,4), 2, padding=1)
        self.conv3 = nn.Conv2d(64, 128, (4,4), 2, padding=1)
        self.conv4 = nn.Conv2d(128, 128, (4,4), 2, padding=1)
        self.linear = nn.Linear(2048, 256)
        self.linear_mu = nn.Linear(256, self.latents)
        self.linear_sigma = nn.Linear(256, self.latents)
        self.relu = nn.ReLU()

    def forward(self, x):
        """
        Returns mean and standard deviation to parameterize sigmoid,
        and final layer to compute environment
        """
        x = self.relu(self.conv1(x)) # (batch_size, 64, 32, 32)
        x = self.relu(self.conv2(x)) # (batch_size, 64, 16, 16)
        x = self.relu(self.conv3(x)) # (batch_size, 128, 8, 8)
        x = self.relu(self.conv4(x)) # (batch_size, 128, 4, 4)
        x = x.reshape(-1, 2048)
        final = self.relu(self.linear(x))
        mu = self.linear_mu(final)
        sigma = torch.exp(self.linear_sigma(final))
        return mu, sigma, final.detach() #detach to prevent gradient flow

# Cell
class EnvironmentInference(nn.Module):
    def __init__(self, max_environmnets: int, input_dim=256):
        super().__init__()
        self.max_environments = max_environmnets
        self.input_dim = input_dim
        self.linear = nn.Linear(input_dim, max_environmnets)
        self.softmax = nn.Softmax(dim=1)

    def forward(self, final_latent):
        x = self.linear(final_latent)
        return self.softmax(x)

# Cell
def env_dist_to_one_hot(env_dist: torch.Tensor, max_environments: int) -> torch.Tensor:
    """Converts a batch of distributions to a one-hot vector"""
    avg_env_dist = env_dist.mean(dim=0)
    env_idx = torch.argmax(avg_env_dist)
    return F.one_hot(env_idx, num_classes=max_environments)
